# -*- coding: utf-8 -*-
"""HW3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1STaf1PfYdG8OovesEs19y5L4ZinDPU1T
"""

# Problem #1 - Scikit-Learn
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
RANDOM_SEED = 42
tf.random.set_seed(RANDOM_SEED)
#np.random.seed(RANDOM_SEED)
n_samples = 30
train_x = np.linspace(0,20,n_samples)
#train_y = 3.7 * train_x + 14 + 4 * tf.random.normal([n_samples]) #np.random.randn(n_samples)
train_y = 3.7 * train_x + 14 + 4 * np.random.randn(n_samples)
plt.plot(train_x, train_y,'o')

train_x = train_x.reshape(-1, 1)
#train_y = train_y.numpy().reshape(-1, 1)
train_y = train_y.reshape(-1, 1)

from sklearn import linear_model
from sklearn import preprocessing

linreg = linear_model.LinearRegression()
linreg.fit(train_x, train_y)
print(linreg.intercept_)
print(linreg.coef_)

# Problem #1 - TensorFlow
graph = tf.Graph()
with graph.as_default():
  slope = tf.Variable(tf.random.uniform([1], -10.0, 10.0))
  intercept = tf.Variable(tf.zeros([1]))

  train_x = preprocessing.minmax_scale(train_x)
  train_y = preprocessing.minmax_scale(train_y)

  response = slope*train_x + intercept

  cost = tf.reduce_mean(input_tensor=tf.square(response - train_y))
  optimizer = tf.compat.v1.train.GradientDescentOptimizer(0.1).minimize(cost)
  init = tf.compat.v1.global_variables_initializer()

with tf.compat.v1.Session(graph=graph) as session:
  session.run(init)
  for epoch in range(10000):
    session.run(optimizer)

    if (epoch % 1000) == 0:
      m = session.run(slope)
      b = session.run(intercept)
      c =  session.run(cost)
      print(epoch, c, m, b)

  print("Slope = ", session.run(slope))
  print("Intercept = ", session.run(intercept))

  slopes = session.run(slope)
  intercepts = session.run(intercept)

  print(preprocessing.minmax_scale(slopes))
  print(preprocessing.minmax_scale(intercepts))

import keras as ks
from keras.models import Sequential
from keras.layers import Dense

model = Sequential()
model.add(Dense(1, input_dim=1, kernel_initializer='normal', activation='linear'))

model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mse'])
model.summary()

hist = model.fit(train_x, train_y, epochs=2000)

weightBias = model.layers[0].get_weights()
print('Weight =', weightBias[0])
print('Bias =', weightBias[1])

# Problem #3 - Scikit-Learn
import pandas as pd
from google.colab import files
uploaded = files.upload()

data = pd.read_csv('00 kc_house_data.csv')
data.head()

pred_vars_sk1 = data[['bedrooms','sqft_living']]

target = data[['price']]

linreg = linear_model.LinearRegression()
linreg.fit(pred_vars_sk1, target)
print(linreg.intercept_)
print(linreg.coef_)

# Problem #3 - TensorFlow
graph = tf.Graph()
with graph.as_default():
  x1 = data[['bedrooms']]
  x2 = data[['sqft_living']]
  y = data[['price']]
  W1 = tf.Variable(np.random.randn(), dtype=np.float32, name="weight1")
  W2 = tf.Variable(np.random.randn(), dtype=np.float32, name="weight2")
  B = tf.Variable(np.random.randn(), dtype=np.float32, name="bias")

  x1 = preprocessing.minmax_scale(x1)
  x2 = preprocessing.minmax_scale(x2)
  target = preprocessing.minmax_scale(target)

  computed_y = W1*x1 + W2*x2 + B

  cost = tf.reduce_mean(input_tensor=tf.square(computed_y - target))
  optimizer = tf.compat.v1.train.GradientDescentOptimizer(0.1).minimize(cost)
  init = tf.compat.v1.global_variables_initializer()

  with tf.compat.v1.Session(graph=graph) as session:
    session.run(init)
    for epoch in range(100000):
      session.run(optimizer)

      if (epoch % 10000) == 0:
        w1 = session.run(W1)
        w2 = session.run(W2)
        b = session.run(B)
        c =  session.run(cost)
        print(epoch, c, w1, w2, b)

    print("Weight1 = ", session.run(W1))
    print("Weight2 = ", session.run(W2))
    print("Bias = ", session.run(B))

model = Sequential()
model.add(Dense(1, input_dim=2, kernel_initializer='normal', activation='linear'))

model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mse'])
model.summary()

print(x1.shape)
print(target.shape)

x1x2 = np.concatenate((x1,x2),axis=1)
print(x1x2.shape)

#epochs = 1000
hist = model.fit(x1x2, target, epochs=1000)

weightBias = model.layers[0].get_weights()
print('Weights =', weightBias[0])
print('Bias =', weightBias[1])