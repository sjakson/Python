{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# IL0: Number of inputs to Layer 0\n",
    "# NL0: Number of neurons in Layer 0\n",
    "IL0 = 4\n",
    "NL0 = 4\n",
    "\n",
    "# IL1: Number of inputs to Layer 1\n",
    "# NL1: Number of neurons in Layer 1\n",
    "IL1 = 4\n",
    "NL1 = 4\n",
    "\n",
    "# IL2: Number of inputs to Layer 2\n",
    "# NL2: Number of neurons in Layer 2\n",
    "IL2 = 4\n",
    "NL2 = 1\n",
    "\n",
    "# Layer 0 is input layer so W0 is identity matrix while B0 is zero matrix.\n",
    "# Layer 0 in a way simply reproduces its inputs at the output\n",
    "B0 = np.zeros((NL0,1))\n",
    "W0 = np.identity((NL0))\n",
    "\n",
    "# Set a seed for the random number generator so that the cost function does\n",
    "# not change in successive runs. \n",
    "np.random.seed(0)\n",
    "\n",
    "# Create B1 and W1\n",
    "B1 = np.zeros((NL1,1))\n",
    "W1 = np.identity((NL1))\n",
    "\n",
    "# Create B2 and W2\n",
    "B2 = np.ones((NL2,1))\n",
    "W2 = np.zeros((NL2,IL2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y, yhat):\n",
    "    return -((1-y)*np.log(1-yhat)+y*np.log(yhat))\n",
    "\n",
    "def unity(yhat):    \n",
    "    return yhat\n",
    "\n",
    "def sigmoid(yhat):    \n",
    "    return 1/(1+np.exp(-yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jcost = 0.00023614634211970533\n",
      "B2 =  [[0.26137148]]\n",
      "W2 =  [[-1.17931957 -3.9147563   5.92582369  2.76429617]]\n"
     ]
    }
   ],
   "source": [
    "g = 100000\n",
    "alpha = 0.05\n",
    "\n",
    "X = np.loadtxt('iristrain-1.csv',delimiter=',',skiprows=1,usecols=np.arange(0,4))\n",
    "X = np.transpose(X)\n",
    "\n",
    "Y = np.loadtxt('iristrain-1.csv',delimiter=',',skiprows=1,usecols=4)\n",
    "Y = np.transpose(Y)\n",
    "\n",
    "m = X.shape[1]\n",
    "\n",
    "J = np.zeros(g).reshape(1,g)\n",
    "\n",
    "for h in range(g):\n",
    "    X0 = X         # Assign input vector to the input of Layer 0 (unit activation)       \n",
    "    G0 = np.dot(W0, X0) + B0 # Determine G0   \n",
    "    H0 = unity(G0)    # Apply activation function of Layer 0\n",
    "    X1 = H0\n",
    "    G1 = np.dot(W1, X1) + B1 # Determine G1   \n",
    "    H1 = unity(G1)    # Apply activation function of Layer 1 (unit activation)\n",
    "    X2 = H1\n",
    "    G2 = np.dot(W2, X2) + B2 # Determine G2   \n",
    "    H2 = sigmoid(G2)    # Apply activation function of Layer 2 (sigmoid activation)\n",
    "    Yhat = H2\n",
    "\n",
    "    J[0,h] = (1/m)*np.sum(loss(Y, Yhat))\n",
    "    \n",
    " # Determine derivatives using the code from past Logistic Regression assignment\n",
    " # Use update formula to update W2 and B2\n",
    " # Loop\n",
    "\n",
    "    dJdw = np.zeros((1,IL2))\n",
    "    dJdb = 0 \n",
    "    \n",
    "    dJdz = Yhat - Y\n",
    "    dJdb = (1/m)*np.sum(dJdz)  \n",
    "    dJdw = (1/m)*np.dot(dJdz,np.transpose(X))\n",
    "    \n",
    "    B2 -= alpha * dJdb\n",
    "    W2 -= alpha * dJdw\n",
    "\n",
    "print(\"Jcost = {}\".format(J[0,g-1]))\n",
    "print(\"B2 = \",B2)\n",
    "print(\"W2 = \",W2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jcost = 0.00010201092701845569\n"
     ]
    }
   ],
   "source": [
    "# Read Iristest-1.csv into X0 (only inputs) and into Y (the output)\n",
    "\n",
    "X = np.loadtxt('iristest-1.csv',delimiter=',',skiprows=1,usecols=np.arange(0,4))\n",
    "X = np.transpose(X)\n",
    "\n",
    "Y = np.loadtxt('iristest-1.csv',delimiter=',',skiprows=1,usecols=4)\n",
    "Y = np.transpose(Y)\n",
    "\n",
    "m = X.shape[1]\n",
    "\n",
    "X0 = X         # Assign input vector to the input of Layer 0 (unit activation)       \n",
    "G0 = np.dot(W0, X0) + B0 # Determine G0   \n",
    "H0 = unity(G0)    # Apply activation function of Layer 0\n",
    "X1 = H0\n",
    "G1 = np.dot(W1, X1) + B1 # Determine G1   \n",
    "H1 = unity(G1)    # Apply activation function of Layer 1 (unit activation)\n",
    "X2 = H1\n",
    "G2 = np.dot(W2, X2) + B2 # Determine G2   \n",
    "H2 = sigmoid(G2)    # Apply activation function of Layer 2 (sigmoid activation)\n",
    "Yhat = H2\n",
    "\n",
    "J = (1/m)*np.sum(loss(Y, Yhat))\n",
    "\n",
    "print(\"Jcost = {}\".format(J))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
